# network architecture
encoder: transformer
encoder_conf:
    output_size: 256    # dimension of attention
    attention_heads: 4
    linear_units: 2048  # the number of units of position-wise feed forward
    num_blocks: 12      # the number of encoder blocks
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.0
    input_layer: "conv2d" # encoder input type, you can chose conv2d, conv2d6 and conv2d8
    normalize_before: True
    feature_norm : True
    pos_enc_layer_type: 'abs_pos'

# decoder related
decoder: transformer
decoder_conf:
    attention_heads: 4
    linear_units: 2048
    num_blocks: 6
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.0
    src_attention_dropout_rate: 0.0

# hybrid CTC/attention
model_conf:
    ctc_weight: 0.3     # Mindspore has some errors for CTC loss computation
    lsm_weight: 0.1     # label smoothing option
    length_normalized_loss: False

# feature extraction
collate_conf:
    # feature level config
    feature_extraction_conf:
        feature_type: 'fbank'
        mel_bins: 80
        frame_shift: 10
        frame_length: 25
        using_pitch: False
    feature_dither: 0.0 # add dither [-feature_dither,feature_dither] on fbank feature
    # data augmentation config
    use_speed_perturb: False
    use_spec_aug: False
    spec_aug_conf:
        warp_for_time: False
        num_t_mask: 2
        num_f_mask: 2
        max_t: 50
        max_f: 10
        max_w: 80
    use_dynamic_chunk: False
    use_dynamic_left_chunk: False
    decoding_chunk_size: 0
    static_chunk_size: 0
    num_decoding_left_chunks: -1

# dataset related
dataset_conf:
    sample_rate: 16000
    max_length: 3000
    min_length: 0
    token_max_length: 30
    token_min_length: 1
    shuffle: True

grad_clip: 5
accum_grad: 1
max_epoch: 30
log_interval: 100

optim: adam
optim_conf:
    lr: 0.001
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 5000

# train option
exp_name: default
train_data: "/path/train/format.data"
eval_data: "/path/dev/format.data"
save_checkpoint: True
save_checkpoint_epochs: 10
save_checkpoint_steps: 460
keep_checkpoint_max: 30
save_checkpoint_path: "./"
device_target: "Ascend"
is_distributed: False
mixed_precision: True
ckpt_file: ""
save_graphs: False
training_with_eval: True

# decode option
test_data: "/path/test/format.data"
dict: "/path/lang_char.txt"
decode_ckpt: "avg_5.ckpt"
decode_mode: "attention"
full_graph: True
decode_batch_size: 1
ctc_weight: 0.0
beam_size: 10
penalty: 0.0

# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: "obs://speech/corpus/aishell1"            # dataset path in OBS
train_url: "obs://speech/code/asr/workspace/"       # workspace path in OBS
checkpoint_url: ""                                  # pre-train ckpt in OBS
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
need_modelarts_dataset_unzip: False
modelarts_dataset_unzip_name: "corpora"
mnt_enable: False
ak: ""
sk: ""
server: ""

# mindinsight config
enable_profiling: False
enable_summary: True

# Config description for each option
use_dynamic_chunk:      # 'whether to use dynamic chunk or not, default: False'
use_dynamic_left_chunk: # 'whether to use dynamic left chunk for training, default: False'
decoding_chunk_size:    # 'ecoding chunk size for dynamic chunk, it is
                        # 0: default for training, use random dynamic chunk.
                        # <0: for decoding, use full chunk.
                        # >0: for decoding, use fixed chunk size as set.'
static_chunk_size:      # 'chunk size for static chunk training/decoding if it is greater than 0,
                        # if use_dynamic_chunk is true, this parameter will be ignored'
num_decoding_left_chunks: # 'number of left chunks, this is for decoding, the chunk size is decoding_chunk_size.
                          # >=0: use num_decoding_left_chunks
                          # <0: use all left chunks'
